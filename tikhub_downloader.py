#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TikHub å¤šå¹³å°ä¸‹è½½å™¨ - ç»Ÿä¸€å‘½ä»¤è¡Œå…¥å£

æ”¯æŒçš„å¹³å°:
- Instagram (instagram.com)
- å°çº¢ä¹¦ (xiaohongshu.com, xhslink.com)
- æ›´å¤šå¹³å°å¼€å‘ä¸­...

ç”¨æ³•:
  # è‡ªåŠ¨æ£€æµ‹å¹³å°
  python tikhub_downloader.py --url "https://www.instagram.com/natgeo/"

  # æ‰¹é‡ä¸‹è½½ï¼ˆä»æ–‡ä»¶ï¼‰
  python tikhub_downloader.py --accounts-file data/accounts.txt

  # åªä¸‹è½½å›¾ç‰‡
  python tikhub_downloader.py --url "..." --images-only

  # åªä¸‹è½½è§†é¢‘
  python tikhub_downloader.py --url "..." --videos-only

  # æŒ‡å®šåª’ä½“ç±»å‹
  python tikhub_downloader.py --url "..." --media-types image,video
"""

import argparse
import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv

from downloader import (
    MediaType,
    MediaDownloader,
    detect_platform,
    get_platform_client,
    PLATFORM_REGISTRY,
)

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


def load_accounts_from_file(file_path: Path) -> List[Dict[str, Any]]:
    """
    ä»æ–‡ä»¶åŠ è½½è´¦å·åˆ—è¡¨

    æ”¯æŒæ ¼å¼:
    1. JSON æ•°ç»„: [{"url": "..."}, ...]
    2. JSON å¯¹è±¡ï¼ˆåˆ†ç±»ï¼‰: {"category1": [...], ...}
    3. çº¯æ–‡æœ¬: æ¯è¡Œä¸€ä¸ª URL
    """
    if not file_path.exists():
        raise FileNotFoundError(f"è´¦å·æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    content = file_path.read_text(encoding="utf-8").strip()

    try:
        data = json.loads(content)

        if isinstance(data, list):
            accounts = []
            for item in data:
                if isinstance(item, dict):
                    accounts.append(item)
                elif isinstance(item, str):
                    accounts.append({"url": item})
            return accounts

        elif isinstance(data, dict):
            accounts = []
            for category, items in data.items():
                if isinstance(items, list):
                    for item in items:
                        if isinstance(item, dict):
                            item["category"] = category
                            accounts.append(item)
                        elif isinstance(item, str):
                            accounts.append({"url": item, "category": category})
            return accounts

    except json.JSONDecodeError:
        # çº¯æ–‡æœ¬æ ¼å¼
        accounts = []
        for line in content.split("\n"):
            line = line.strip()
            if line and not line.startswith("#"):
                accounts.append({"url": line})
        return accounts

    return []


def load_config(config_path: Path) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if config_path.exists():
        try:
            return json.loads(config_path.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
    return {}


def get_api_key(config: Dict[str, Any]) -> str:
    """è·å– API å¯†é’¥"""
    api_key = (
        os.getenv("TIKHUB_API_KEY") or
        os.getenv("HENGHENGMAO_API_KEY") or
        config.get("tikhub", {}).get("api_key", "") or
        config.get("henghengmao", {}).get("api_key", "")
    )

    if not api_key:
        raise ValueError(
            "ç¼ºå°‘ TikHub API å¯†é’¥ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡:\n"
            "  export TIKHUB_API_KEY='your_api_key'\n"
            "æˆ–åœ¨ config/config.json ä¸­é…ç½®"
        )

    return api_key


def get_backup_api_keys(config: Dict[str, Any]) -> List[str]:
    """è·å–å¤‡ç”¨ API å¯†é’¥åˆ—è¡¨"""
    backup_keys = []

    # ä»ç¯å¢ƒå˜é‡åŠ è½½
    backup_key = os.getenv("TIKHUB_API_KEY_BACKUP")
    if backup_key:
        backup_keys.append(backup_key)

    # æ”¯æŒå¤šä¸ªå¤‡ç”¨ Key: TIKHUB_API_KEY_BACKUP_1, TIKHUB_API_KEY_BACKUP_2, ...
    for i in range(1, 10):
        key = os.getenv(f"TIKHUB_API_KEY_BACKUP_{i}")
        if key:
            backup_keys.append(key)

    # ä»é…ç½®æ–‡ä»¶åŠ è½½
    config_backup_keys = config.get("tikhub", {}).get("backup_api_keys", [])
    if isinstance(config_backup_keys, list):
        backup_keys.extend(config_backup_keys)

    return backup_keys


def parse_media_types(args) -> List[MediaType]:
    """è§£æåª’ä½“ç±»å‹å‚æ•°"""
    # å¿«æ·é€‰é¡¹ä¼˜å…ˆ
    if args.images_only:
        return [MediaType.IMAGE]
    if args.videos_only:
        return [MediaType.VIDEO]
    if args.audio_only:
        return [MediaType.AUDIO]

    # è‡ªå®šä¹‰ç±»å‹
    if args.media_types:
        return MediaType.parse_list(args.media_types)

    # é»˜è®¤ï¼šå›¾ç‰‡å’Œè§†é¢‘
    return [MediaType.IMAGE, MediaType.VIDEO]


async def download_account(
    api_key: str,
    url: str,
    output_dir: Path,
    media_types: List[MediaType],
    max_posts: Optional[int] = None,
    max_items: Optional[int] = None,
    concurrent: int = 10,
    skip_existing: bool = True,
    backup_api_keys: List[str] = None
) -> Dict[str, Any]:
    """ä¸‹è½½å•ä¸ªè´¦å·çš„å†…å®¹"""
    # æ£€æµ‹å¹³å°
    platform = detect_platform(url)
    if not platform:
        return {
            "url": url,
            "success": False,
            "error": "æ— æ³•è¯†åˆ«çš„å¹³å° URL"
        }

    # è·å–å¹³å°å®¢æˆ·ç«¯
    client_cls = get_platform_client(platform)
    if not client_cls:
        return {
            "url": url,
            "success": False,
            "error": f"å¹³å° {platform} æš‚ä¸æ”¯æŒ"
        }

    print(f"\n{'='*60}")
    print(f"ğŸ“¥ å¹³å°: {platform.upper()}")
    print(f"ğŸ”— URL: {url}")
    print(f"ğŸ“¦ åª’ä½“ç±»å‹: {', '.join(t.value for t in media_types)}")

    async with client_cls(api_key, backup_api_keys=backup_api_keys) as api:
        # è·å–å¸–å­ï¼ˆå¯¹äºçŸ­é“¾æ¥ï¼Œè¿™ä¼šè§£æå¹¶ç¼“å­˜ç”¨æˆ·ä¿¡æ¯ï¼‰
        posts = await api.get_user_posts(url, max_posts)

        # æå–ç”¨æˆ·åï¼ˆåœ¨è·å–å¸–å­åï¼ŒçŸ­é“¾æ¥çš„ç”¨æˆ·åå¯èƒ½å·²è¢«ç¼“å­˜ï¼‰
        username = api.extract_username_from_url(url) or "unknown"
        print(f"ğŸ‘¤ ç”¨æˆ·: {username}")

        if not posts:
            return {
                "url": url,
                "platform": platform,
                "username": username,
                "success": False,
                "error": "æœªè·å–åˆ°å¸–å­"
            }

        print(f"ğŸ“„ è·å–åˆ° {len(posts)} ä¸ªå¸–å­")

        # æå–åª’ä½“
        all_items = []
        for post in posts:
            items = api.extract_media_from_post(post, media_types)
            all_items.extend(items)
            if max_items and len(all_items) >= max_items:
                all_items = all_items[:max_items]
                break

        # ç»Ÿè®¡åª’ä½“ç±»å‹
        type_counts = {}
        for item in all_items:
            t = item.media_type.value
            type_counts[t] = type_counts.get(t, 0) + 1

        print(f"ğŸ¬ æå–åˆ° {len(all_items)} ä¸ªåª’ä½“: {type_counts}")

        if not all_items:
            return {
                "url": url,
                "platform": platform,
                "username": username,
                "success": True,
                "total": 0,
                "downloaded": 0
            }

        # ä¸‹è½½
        async with MediaDownloader(
            output_dir,
            max_concurrent=concurrent,
            skip_existing=skip_existing
        ) as downloader:
            results = await downloader.download_batch(
                platform=platform,
                username=username,
                items=all_items,
                progress_desc=f"ä¸‹è½½ {username}"
            )

            success_count = sum(1 for s, _ in results if s)
            print(f"âœ… å®Œæˆ: {success_count}/{len(all_items)}")

            return {
                "url": url,
                "platform": platform,
                "username": username,
                "success": True,
                "total": len(all_items),
                "downloaded": success_count,
                "failed": len(all_items) - success_count,
                "stats": downloader.stats.copy()
            }


async def main_async(args):
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®
    config = load_config(Path(args.config))

    # è·å– API å¯†é’¥
    try:
        api_key = get_api_key(config)
    except ValueError as e:
        print(f"âŒ {e}")
        return 1

    # è·å–å¤‡ç”¨ API å¯†é’¥
    backup_api_keys = get_backup_api_keys(config)
    if backup_api_keys:
        print(f"ğŸ”‘ å·²åŠ è½½ {len(backup_api_keys)} ä¸ªå¤‡ç”¨ API Key")

    # å‡†å¤‡è´¦å·åˆ—è¡¨
    accounts = []

    if args.url:
        accounts = [{"url": args.url}]
    elif args.accounts_file:
        accounts = load_accounts_from_file(Path(args.accounts_file))
    else:
        print("âŒ è¯·æŒ‡å®š --url æˆ– --accounts-file")
        return 1

    if not accounts:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆè´¦å·")
        return 1

    # è§£æåª’ä½“ç±»å‹
    media_types = parse_media_types(args)

    print(f"ğŸ“‹ å‡†å¤‡ä¸‹è½½ {len(accounts)} ä¸ªè´¦å·")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“¦ åª’ä½“ç±»å‹: {', '.join(t.value for t in media_types)}")

    # æ˜¾ç¤ºæ”¯æŒçš„å¹³å°
    print(f"ğŸŒ æ”¯æŒå¹³å°: {', '.join(PLATFORM_REGISTRY.keys())}")

    if not args.yes:
        response = input("\næ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
        if response != "y":
            print("å·²å–æ¶ˆ")
            return 0

    output_dir = Path(args.output_dir)

    # å¤„ç†æ¯ä¸ªè´¦å·
    results = []
    for account in accounts:
        url = account.get("url", "")
        if not url:
            continue

        result = await download_account(
            api_key=api_key,
            url=url,
            output_dir=output_dir,
            media_types=media_types,
            max_posts=args.max_posts,
            max_items=args.max_items,
            concurrent=args.concurrent,
            skip_existing=not args.no_skip_existing,
            backup_api_keys=backup_api_keys
        )
        results.append(result)

    # è¾“å‡ºæ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š ä¸‹è½½æ€»ç»“:")
    print(f"{'='*60}")

    total_items = sum(r.get("total", 0) for r in results)
    total_downloaded = sum(r.get("downloaded", 0) for r in results)
    total_failed = sum(r.get("failed", 0) for r in results)

    for result in results:
        if result.get("success"):
            platform = result.get("platform", "?")
            username = result.get("username", "?")
            downloaded = result.get("downloaded", 0)
            total = result.get("total", 0)
            print(f"âœ… [{platform}] {username}: {downloaded}/{total}")
        else:
            error = result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"âŒ {result.get('url', '?')}: {error}")

    print(f"\næ€»è®¡: {total_downloaded}/{total_items} ä¸ªæ–‡ä»¶æˆåŠŸä¸‹è½½")
    if total_failed > 0:
        print(f"å¤±è´¥: {total_failed} ä¸ª")

    return 0


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="TikHub å¤šå¹³å°ä¸‹è½½å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä¸‹è½½ Instagram è´¦å·
  python tikhub_downloader.py --url "https://www.instagram.com/natgeo/"

  # ä¸‹è½½å°çº¢ä¹¦è´¦å·
  python tikhub_downloader.py --url "https://www.xiaohongshu.com/user/profile/xxx"

  # æ‰¹é‡ä¸‹è½½
  python tikhub_downloader.py --accounts-file data/accounts.txt

  # åªä¸‹è½½å›¾ç‰‡
  python tikhub_downloader.py --url "..." --images-only

  # åªä¸‹è½½è§†é¢‘
  python tikhub_downloader.py --url "..." --videos-only

  # æŒ‡å®šåª’ä½“ç±»å‹
  python tikhub_downloader.py --url "..." --media-types image,video

æ”¯æŒçš„å¹³å°:
  - Instagram (instagram.com)
  - å°çº¢ä¹¦ (xiaohongshu.com, xhslink.com)
  - æ›´å¤šå¹³å°å¼€å‘ä¸­...

ç¯å¢ƒå˜é‡:
  TIKHUB_API_KEY - TikHub API å¯†é’¥
        """
    )

    # è¾“å…¥é€‰é¡¹
    input_group = parser.add_mutually_exclusive_group()
    input_group.add_argument(
        "--url",
        help="å•ä¸ªè´¦å· URLï¼ˆè‡ªåŠ¨æ£€æµ‹å¹³å°ï¼‰"
    )
    input_group.add_argument(
        "--accounts-file",
        help="è´¦å·åˆ—è¡¨æ–‡ä»¶ï¼ˆæ”¯æŒ JSON æˆ–çº¯æ–‡æœ¬ï¼‰"
    )

    # è¾“å‡ºé€‰é¡¹
    parser.add_argument(
        "--output-dir",
        default="output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: outputï¼‰"
    )
    parser.add_argument(
        "--config",
        default="config/config.json",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config/config.jsonï¼‰"
    )

    # åª’ä½“ç±»å‹é€‰é¡¹
    media_group = parser.add_argument_group("åª’ä½“ç±»å‹")
    media_group.add_argument(
        "--media-types",
        help="åª’ä½“ç±»å‹ï¼Œé€—å·åˆ†éš” (image,video,audio)"
    )
    media_group.add_argument(
        "--images-only",
        action="store_true",
        help="åªä¸‹è½½å›¾ç‰‡"
    )
    media_group.add_argument(
        "--videos-only",
        action="store_true",
        help="åªä¸‹è½½è§†é¢‘"
    )
    media_group.add_argument(
        "--audio-only",
        action="store_true",
        help="åªä¸‹è½½éŸ³é¢‘"
    )

    # ä¸‹è½½é€‰é¡¹
    download_group = parser.add_argument_group("ä¸‹è½½é€‰é¡¹")
    download_group.add_argument(
        "--max-posts",
        type=int,
        help="æ¯ä¸ªè´¦å·æœ€å¤šä¸‹è½½çš„å¸–å­æ•°"
    )
    download_group.add_argument(
        "--max-items",
        type=int,
        help="æ¯ä¸ªè´¦å·æœ€å¤šä¸‹è½½çš„åª’ä½“æ•°"
    )
    download_group.add_argument(
        "--concurrent",
        type=int,
        default=10,
        help="å¹¶å‘ä¸‹è½½æ•°ï¼ˆé»˜è®¤: 10ï¼‰"
    )
    download_group.add_argument(
        "--no-skip-existing",
        action="store_true",
        help="ä¸è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶"
    )

    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        "--yes", "-y",
        action="store_true",
        help="è·³è¿‡ç¡®è®¤æç¤º"
    )

    args = parser.parse_args()
    exit_code = asyncio.run(main_async(args))
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
